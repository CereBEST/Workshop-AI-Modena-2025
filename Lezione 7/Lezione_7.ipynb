{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gphKiLU8uJ8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ===============================================================\n",
        "# ğŸ“˜ \"Oltre il prompt: guida pratica allâ€™intelligenza artificiale\n",
        "#     per studenti e programmatori\"\n",
        "# Â© 2025 Francesco Di Gruttola\n",
        "#\n",
        "# Licensed under the Creative Commons\n",
        "# Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\n",
        "# ğŸ‘‰ https://creativecommons.org/licenses/by-nc-nd/4.0/\n",
        "#\n",
        "# Repository: https://github.com/CereBEST/Workshop-AI-Modena-2025.git\n",
        "# ==============================================================="
      ],
      "metadata": {
        "id": "Z3BXUsCA6N0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lezione 7 - Computer Vision e NLP"
      ],
      "metadata": {
        "id": "E0v5k63HtjT7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a76ed278"
      },
      "source": [
        "## 1. Reti Convolutive (CNN) con esempio MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM_pdgiNSYxX"
      },
      "source": [
        "Le **Convolutional Neural Networks (CNN)** sono un tipo di rete neurale progettata per lavorare con immagini e altri dati con struttura spaziale.  \n",
        "Sono alla base di quasi tutte le moderne tecniche di Computer Vision.\n",
        "\n",
        "### 1. PerchÃ© servono le CNN?\n",
        "\n",
        "Prendiamo un'immagine MNIST 28Ã—28 pixel.  \n",
        "Se la \"flatteniamo\", diventa un vettore di **784 valori**.\n",
        "\n",
        "In una rete Dense:\n",
        "- ogni neurone sarebbe collegato a tutti i 784 pixel  \n",
        "- i pesi crescono molto rapidamente  \n",
        "- il modello diventa enorme e difficile da addestrare  \n",
        "\n",
        "E con immagini piÃ¹ grandi (es. 100Ã—100Ã—3 RGB) diventa impossibile.\n",
        "\n",
        "Le immagini hanno **struttura**, non sono solo liste di numeri:\n",
        "- pixel vicini sono spesso collegati\n",
        "- molte forme si ripetono (bordi, curve, angoli)\n",
        "- gli oggetti possono essere ovunque nellâ€™immagine\n",
        "\n",
        "Le CNN sfruttano proprio questo.\n",
        "\n",
        "### 2. Local receptive field (campo recettivo locale)\n",
        "\n",
        "In una CNN ogni neurone guarda **solo una piccola regione** dellâ€™immagine, ad esempio 3Ã—3 o 5Ã—5 pixel.\n",
        "\n",
        "Questo rispecchia il modo in cui vediamo noi:\n",
        "- prima riconosciamo pattern semplici (bordi)\n",
        "- poi pezzi di forma\n",
        "- poi oggetti completi\n",
        "\n",
        "### 3. Cosâ€™Ã¨ una convoluzione?\n",
        "\n",
        "Una **convoluzione** Ã¨ unâ€™operazione che combina:\n",
        "- un **filtro (kernel)**, es. 3Ã—3\n",
        "- una porzione dellâ€™immagine della stessa dimensione\n",
        "\n",
        "Ecco un esempio di filtro:\n",
        "- [-1, 0, +1][-1, 0, +1][-1, 0, +1]\n",
        "\n",
        "Questo filtro viene â€œfatto scorrereâ€ su tutta lâ€™immagine.\n",
        "\n",
        "Per ogni posizione:\n",
        "1. si moltiplicano pixel immagine Ã— valori del filtro  \n",
        "2. si sommano i risultati  \n",
        "3. si ottiene un numero â†’ un pixel della **feature map**\n",
        "\n",
        "### 4. Weight sharing (condivisione dei pesi)\n",
        "\n",
        "Il concetto piÃ¹ potente delle CNN:\n",
        "- lo **stesso filtro** viene applicato su tutta lâ€™immagine\n",
        "- non serve un filtro diverso per ogni posizione\n",
        "\n",
        "Questo riduce i parametri in modo enorme.\n",
        "\n",
        "Esempio:\n",
        "- Dense con 784 input e 128 neuroni â†’ 784Ã—128 = 100.352 pesi  \n",
        "- Conv2D con 32 filtri 3Ã—3 â†’ 32Ã—(3Ã—3Ã—1) = **288 pesi**\n",
        "\n",
        "Da 100.000 pesi a 288!\n",
        "\n",
        "Senza perdere capacitÃ : il filtro riconosce il pattern ovunque appaia.\n",
        "\n",
        "### 5. Feature map: cosa sono?\n",
        "\n",
        "Ogni filtro produce un'immagine trasformata detta **feature map**.\n",
        "\n",
        "Esempi di ciÃ² che i filtri possono imparare:\n",
        "- bordi verticali\n",
        "- bordi orizzontali\n",
        "- angoli\n",
        "- linee curve\n",
        "- texture\n",
        "\n",
        "Le feature map rappresentano **cosa la rete ha trovato interessante** nellâ€™immagine.\n",
        "\n",
        "### 6. Stride\n",
        "\n",
        "Lo **stride** controlla di quanto si sposta il filtro.\n",
        "\n",
        "- `stride = 1` â†’ si sposta di 1 pixel alla volta  \n",
        "- `stride = 2` â†’ salta pixel â†’ output piÃ¹ piccolo\n",
        "\n",
        "Output piÃ¹ piccolo = meno calcoli = rete piÃ¹ veloce.\n",
        "\n",
        "### 7. Padding (same vs valid)\n",
        "\n",
        "Quando un filtro 3Ã—3 scorre su unâ€™immagine 28Ã—28:\n",
        "\n",
        "- senza padding â†’ risultato 26Ã—26  \n",
        "- perdiamo informazioni ai bordi\n",
        "\n",
        "Il **padding** aggiunge una cornice artificiale (di solito 0).\n",
        "\n",
        "- `padding=\"same\"` â†’ output stessa dimensione dellâ€™input  \n",
        "- `padding=\"valid\"` â†’ nessun padding, output piÃ¹ piccolo\n",
        "\n",
        "### 8. Pooling\n",
        "\n",
        "Il **Pooling** riduce la dimensione delle feature map.\n",
        "\n",
        "Il piÃ¹ comune Ã¨ il **MaxPooling 2Ã—2**:\n",
        "\n",
        "- [2, 1][7, 3] -> 7\n",
        "\n",
        "Per ogni blocco 2Ã—2, prende il valore massimo.\n",
        "\n",
        "Effetti importanti:\n",
        "- riduce dimensioni\n",
        "- riduce numero di parametri\n",
        "- rende la rete piÃ¹ robusta a piccole traslazioni\n",
        "\n",
        "### 9. Come una CNN costruisce la comprensione dellâ€™immagine\n",
        "\n",
        "Le CNN imparano rappresentazioni **gerarchiche**:\n",
        "\n",
        "Primo layer â†’ pattern semplici\n",
        "- bordi\n",
        "- gradienti\n",
        "- linee\n",
        "\n",
        "Secondo layer â†’ pattern intermedi\n",
        "- curve\n",
        "- angoli complessi\n",
        "- pezzi di forme\n",
        "\n",
        "Terzo layer â†’ concetti astratti\n",
        "- silhouette\n",
        "- forme significative\n",
        "- parti dellâ€™oggetto\n",
        "\n",
        "Ogni layer costruisce sopra il precedente.\n",
        "\n",
        "### 10. Come impara una CNN?\n",
        "\n",
        "Il processo Ã¨ lo stesso delle reti classiche:\n",
        "1. predizione\n",
        "2. calcolo dellâ€™errore\n",
        "3. backpropagation\n",
        "4. aggiornamento dei pesi\n",
        "\n",
        "La differenza Ã¨ che il modello aggiorna:\n",
        "- i pesi dei filtri\n",
        "- non connessioni neurone-per-neurone  \n",
        "\n",
        "I filtri imparano automaticamente cosa estrarre dalle immagini.\n",
        "\n",
        "### 11. PerchÃ© le CNN funzionano cosÃ¬ bene?\n",
        "\n",
        "- sfruttano le proprietÃ  locali delle immagini  \n",
        "- usano pochi pesi grazie al weight sharing  \n",
        "- costruiscono gerarchie di feature  \n",
        "- sono robuste a traslazioni, rotazioni leggere, rumore  \n",
        "- imparano pattern ricorrenti ovunque appaiano  \n",
        "\n",
        "Sono molto piÃ¹ adatte delle dense per immagini.\n",
        "\n",
        "### 12. Struttura tipica di una CNN\n",
        "\n",
        "Input -> Convoluzione -> ReLU -> Convoluzione -> ReLU -> MaxPooling -> Flatten -> Dense -> Output\n",
        "\n",
        "Questa struttura Ã¨ alla base di modelli come:\n",
        "- LeNet\n",
        "- AlexNet\n",
        "- VGG\n",
        "- ResNet (con skip connections)\n",
        "\n",
        "### 13. Ruolo della ReLU\n",
        "\n",
        "ReLU = **Rectified Linear Unit**\n",
        "\n",
        "ReLU(X) = max(0, X)\n",
        "\n",
        "PerchÃ© Ã¨ importante:\n",
        "- evita problemi di saturazione (come sigmoid/tanh)\n",
        "- permette gradienti piÃ¹ stabili\n",
        "- Ã¨ veloce da calcolare\n",
        "- aiuta a costruire rappresentazioni sparse ed efficienti\n",
        "\n",
        "### 14. CNN per MNIST (concettualmente)\n",
        "\n",
        "La CNN che useremo ha:\n",
        "\n",
        "- **Conv2D(32, 3Ã—3)** â†’ riconosce bordi  \n",
        "- **Conv2D(64, 3Ã—3)** â†’ combina i bordi in forme  \n",
        "- **MaxPooling(2Ã—2)** â†’ riduce dimensione  \n",
        "- **Flatten**  \n",
        "- **Dense(128, ReLU)**  \n",
        "- **Dense(10, softmax)** â†’ classifica la cifra\n",
        "\n",
        "Raggiunge facilmente >99% di accuratezza.\n",
        "\n",
        "### Riepilogo\n",
        "\n",
        "Le **Convolutional Neural Networks (CNN)** sono progettate per lavorare con dati con struttura spaziale (immagini).\n",
        "\n",
        "Concept chiave:\n",
        "\n",
        "1. **Local receptive field**: ogni neurone convolutivo vede solo una piccola finestra dell'immagine.\n",
        "2. **Convoluzione**: un filtro (kernel) scorre sull'immagine ed estrae bordi, texture, pattern.\n",
        "3. **Weight sharing**: lo stesso filtro viene applicato in tutte le posizioni â†’ pochi parametri, invarianti a traslazioni.\n",
        "4. **Pooling (es. MaxPooling)**: riduce la risoluzione spaziale, aumenta la robustezza a piccoli spostamenti.\n",
        "- Le CNN guardano **piccoli pezzi** dellâ€™immagine alla volta\n",
        "- Usano **filtri** che imparano automaticamente cosa estrarre\n",
        "- Lo stesso filtro viene usato ovunque (weight sharing)\n",
        "- Costruiscono una **gerarchia**:\n",
        "  - bordi â†’ forme â†’ oggetti\n",
        "- Sono molto piÃ¹ efficienti delle reti Dense sulle immagini\n",
        "- Sono lo strumento principale del Deep Learning per la visione artificiale\n",
        "Architettura tipica:\n",
        "\n",
        "- Conv2D + ReLU\n",
        "- Conv2D + ReLU\n",
        "- MaxPooling2D\n",
        "- Flatten\n",
        "- Dense finale con softmax (per classificazione)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebab1579"
      },
      "source": [
        "\n",
        "### 1.1 Preparazione dei dati per la CNN (MNIST)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73wD7yIdbcDF",
        "outputId": "074abee8-ff6e-49c6-cfa6-edeea9c55af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eedf6583",
        "outputId": "964f4d62-7e56-4e53-9362-37d384c7fca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Shape training set CNN: (60000, 28, 28, 1)\n",
            "Shape test set CNN: (10000, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Ricarichiamo MNIST (nel formato originale) e prepariamo per CNN\n",
        "(x_train_cnn, y_train_cnn), (x_test_cnn, y_test_cnn) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train_cnn = x_train_cnn.astype(\"float32\") / 255.0\n",
        "x_test_cnn = x_test_cnn.astype(\"float32\") / 255.0\n",
        "\n",
        "# Aggiungiamo il canale (grayscale)\n",
        "x_train_cnn = x_train_cnn[..., tf.newaxis]  # shape: (N, 28, 28, 1)\n",
        "x_test_cnn = x_test_cnn[..., tf.newaxis]\n",
        "\n",
        "print(\"Shape training set CNN:\", x_train_cnn.shape)\n",
        "print(\"Shape test set CNN:\", x_test_cnn.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dad9963"
      },
      "source": [
        "### 1.2 Definizione della CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "b374bdb9",
        "outputId": "02e93185-4966-483d-ec5d-2288f72051ac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚           \u001b[38;5;34m320\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚        \u001b[38;5;34m18,496\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9216\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚     \u001b[38;5;34m1,179,776\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚         \u001b[38;5;34m1,290\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9216</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,776</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,199,882\u001b[0m (4.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,199,882</span> (4.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,199,882\u001b[0m (4.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,199,882</span> (4.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "inputs_cnn = keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "x = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inputs_cnn)\n",
        "x = layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs_cnn = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model_cnn = keras.Model(inputs_cnn, outputs_cnn)\n",
        "\n",
        "model_cnn.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model_cnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c6c1a77"
      },
      "source": [
        "### 1.3 Addestramento della CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa3e6af8",
        "outputId": "586130fa-9bba-4d86-bacb-ec2d12c5f9d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 153ms/step - accuracy: 0.8657 - loss: 0.4234 - val_accuracy: 0.9850 - val_loss: 0.0575\n",
            "Epoch 2/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 154ms/step - accuracy: 0.9738 - loss: 0.0905 - val_accuracy: 0.9887 - val_loss: 0.0429\n",
            "Epoch 3/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 149ms/step - accuracy: 0.9808 - loss: 0.0648 - val_accuracy: 0.9902 - val_loss: 0.0368\n",
            "Epoch 4/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 148ms/step - accuracy: 0.9840 - loss: 0.0510 - val_accuracy: 0.9908 - val_loss: 0.0328\n",
            "Epoch 5/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 150ms/step - accuracy: 0.9860 - loss: 0.0443 - val_accuracy: 0.9913 - val_loss: 0.0315\n"
          ]
        }
      ],
      "source": [
        "\n",
        "history_cnn = model_cnn.fit(\n",
        "    x_train_cnn, y_train_cnn,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_split=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9235225"
      },
      "source": [
        "### 1.4 Valutazione della CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dcd366e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5eb837e-cb35-4c52-fb6d-496e26dbe2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9891 - loss: 0.0354\n",
            "Test accuracy (CNN su MNIST): 0.9915000200271606\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_loss_cnn, test_acc_cnn = model_cnn.evaluate(x_test_cnn, y_test_cnn)\n",
        "print(\"Test accuracy (CNN su MNIST):\", test_acc_cnn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb0051c0"
      },
      "source": [
        "### 1.5 Visualizzare i filtri del primo layer convolutivo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe693fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "0cd37921-1909-46dc-b94d-d231cfd14086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape filtri: (3, 3, 1, 32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "first_conv_layer = model_cnn.layers[1]\n",
        "filters, biases = first_conv_layer.get_weights()\n",
        "\n",
        "print(\"Shape filtri:\", filters.shape)  # (3,3,1,32)\n",
        "\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters_norm = (filters - f_min) / (f_max - f_min + 1e-7)\n",
        "\n",
        "n_filters = 6\n",
        "plt.figure(figsize=(10, 3))\n",
        "\n",
        "for i in range(n_filters):\n",
        "    f = filters_norm[:, :, 0, i]\n",
        "    plt.subplot(1, n_filters, i + 1)\n",
        "    plt.imshow(f, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle(\"Primi 6 filtri del primo layer convolutivo\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11bc2fd8"
      },
      "source": [
        "### 1.6 Visualizzare alcune feature map\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4314f668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "75424f36-e30e-4d8b-b851-49849cbdba00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "(1, 28, 28, 1)\n",
            "0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras import models\n",
        "\n",
        "layer_outputs = [layer.output for layer in model_cnn.layers[:4]]\n",
        "activation_model = models.Model(inputs=model_cnn.input, outputs=layer_outputs)\n",
        "\n",
        "img = x_test_cnn[0:1]\n",
        "activations = activation_model.predict(img)\n",
        "\n",
        "layer_names = [layer.name for layer in model_cnn.layers[:4]]\n",
        "\n",
        "first_layer_activation = activations[0]\n",
        "print(first_layer_activation.shape)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(1):\n",
        "    print(i)\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.imshow(first_layer_activation[0, :, :, i], cmap='inferno')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle(\"Alcune feature map del primo layer\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Natural Language Processing (NLP)"
      ],
      "metadata": {
        "id": "rl73veaYyjwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Introduzione a NLP (Natural Language Processing)\n",
        "\n",
        "L'**NLP** si occupa di far \"capire\" il linguaggio naturale alle macchine.\n",
        "\n",
        "Esempi di problemi NLP:\n",
        "- classificazione di testo (spam / non spam, sentiment, topic)\n",
        "- traduzione automatica\n",
        "- riassunto automatico\n",
        "- riconoscimento di entitÃ  (nomi, luoghi, ecc.)\n",
        "- chatbot, Q&A, ecc.\n",
        "\n",
        "#### 1.1 Il problema principale: il testo non Ã¨ numerico\n",
        "\n",
        "Le reti neurali lavorano con **numeri**, non con parole.\n",
        "Quindi il primo passo Ã¨ sempre: **convertire il testo in numeri**.\n",
        "\n",
        "Passi tipici:\n",
        "1. **Pulizia** del testo (minuscole, rimozione punteggiatura, ecc.)\n",
        "2. **Tokenizzazione** â†’ trasformare la frase in una sequenza di \"token\" (parole o sottoparole)\n",
        "3. Creare un **vocabolario** (lista di token ammessi)\n",
        "4. Mappare ogni token a un **intero** (id)\n",
        "5. Ottenere cosÃ¬ una **sequenza di interi** per ogni frase.\n",
        "\n",
        "Esempio:\n",
        "- frase: `\"mi piace molto il deep learning\"`\n",
        "- token: [`\"mi\"`, `\"piace\"`, `\"molto\"`, `\"il\"`, `\"deep\"`, `\"learning\"`]\n",
        "- id: `[12, 47, 85, 5, 102, 333]` (numeri inventati)\n",
        "\n",
        "#### 1.2 PerchÃ© non basta one-hot?\n",
        "\n",
        "Una rappresentazione semplice Ã¨ il **one-hot encoding**:\n",
        "- ogni parola Ã¨ un vettore con tutti 0 tranne un 1 in una posizione\n",
        "\n",
        "Problemi:\n",
        "- vettori enormi (uno per ogni parola del vocabolario)\n",
        "- nessuna informazione di somiglianza (per il modello \"gatto\" e \"cane\" sono completamente diversi)\n",
        "\n",
        "#### 1.3 Word Embedding\n",
        "\n",
        "Un **embedding** Ã¨ una rappresentazione vettoriale densa per i token:\n",
        "- ogni parola viene mappata a un vettore di dimensione fissa (es. 16, 64, 128)\n",
        "- parole simili tendono ad avere vettori simili\n",
        "\n",
        "In Keras esiste un layer apposito:\n",
        "- `Embedding(input_dim=vocab_size, output_dim=embedding_dim)`\n",
        "\n",
        "Questo layer impara **durante il training** quali vettori associare alle parole.\n",
        "\n",
        "#### 1.4 Sequenze e padding\n",
        "\n",
        "Nei modelli di deep learning ci serve che i batch abbiano shape coerenti.\n",
        "\n",
        "Le frasi hanno lunghezze diverse:\n",
        "- \"ciao\" â†’ 1 parola\n",
        "- \"oggi Ã¨ una bellissima giornata\" â†’ 4 parole\n",
        "- ecc.\n",
        "\n",
        "Allora:\n",
        "- scegliamo una lunghezza massima `maxlen`\n",
        "- tagliamo le frasi troppo lunghe\n",
        "- **padding** con zeri quelle piÃ¹ corte\n",
        "\n",
        "Esempio (`maxlen = 5`):\n",
        "\n",
        "- `[12, 47]` â†’ `[0, 0, 12, 47, 0]`  \n",
        "- `[5, 7, 9, 11, 13, 25]` â†’ `[7, 9, 11, 13, 25]` (taglio)\n",
        "\n",
        "In pratica useremo:\n",
        "- un livello di **tokenizzazione** (`TextVectorization`)\n",
        "- un **Embedding**\n",
        "- e poi un modello (Dense, RNN, Transformer, ecc.) sopra.\n",
        "\n",
        "Useremo un mini dataset finto (frasi positive/negative) per mostrare:\n",
        "\n",
        "- TextVectorization\n",
        "- Embedding\n",
        "- GlobalAveragePooling1D per ottenere un vettore di frase"
      ],
      "metadata": {
        "id": "3M7ST2a7ytHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO65aTdd59Qi",
        "outputId": "b4d9e48c-65e9-4ab7-dff0-6e72d13c05f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# Mini dataset di esempio\n",
        "testi = np.array([\n",
        "    \"mi piace molto questo film\",\n",
        "    \"questo film Ã¨ stato noioso\",\n",
        "    \"adoro questo prodotto\",\n",
        "    \"odio profondamente questo prodotto\",\n",
        "    \"esperienza fantastica, sono molto soddisfatto\",\n",
        "    \"pessima esperienza, non lo comprerÃ² mai piÃ¹\"\n",
        "])\n",
        "\n",
        "etichette = np.array([1, 0, 1, 0, 1, 0])  # 1 = positivo, 0 = negativo\n",
        "\n",
        "# Parametri\n",
        "vocab_size = 1000  # massimo numero di token da considerare\n",
        "maxlen = 10  # lunghezza massima delle frasi che il modello usa\n",
        "\n",
        "# Layer di vettorizzazione del testo\n",
        "vectorizer = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=maxlen\n",
        ")\n",
        "\n",
        "# Adattiamo il vocabolario ai nostri testi\n",
        "vectorizer.adapt(testi)\n",
        "\n",
        "# Vediamo il vocabolario\n",
        "vocab = vectorizer.get_vocabulary()\n",
        "print(\"Dimensione vocabolario:\", len(vocab))\n",
        "print(\"Prime 10 parole:\", vocab[:10])\n",
        "\n",
        "# Applichiamo la trasformazione\n",
        "X = vectorizer(testi)\n",
        "print(\"Shape X:\", X.shape)\n",
        "print(\"Esempio di sequenza:\", X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH1OC9Ih5tqk",
        "outputId": "1b71976c-1e7b-4ae9-bc03-bb1755cefed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensione vocabolario: 24\n",
            "Prime 10 parole: ['', '[UNK]', np.str_('questo'), np.str_('prodotto'), np.str_('molto'), np.str_('film'), np.str_('esperienza'), np.str_('Ã¨'), np.str_('stato'), np.str_('sono')]\n",
            "Shape X: (6, 10)\n",
            "Esempio di sequenza: tf.Tensor([18 13  4  2  5  0  0  0  0  0], shape=(10,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modello di classificazione semplice: Embedding + media + Dense\n",
        "\n",
        "embedding_dim = 16  # dimensione del vettore di ogni parola\n",
        "\n",
        "inputs = keras.Input(shape=(maxlen,))\n",
        "x = layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)(inputs)\n",
        "x = layers.GlobalAveragePooling1D()(x)  # media sui token\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model_nlp = keras.Model(inputs, outputs)\n",
        "\n",
        "model_nlp.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model_nlp.summary()\n",
        "\n",
        "history_nlp = model_nlp.fit(\n",
        "    X, etichette,\n",
        "    epochs=30,\n",
        "    batch_size=2,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "loss, acc = model_nlp.evaluate(X, etichette, verbose=0)\n",
        "print(\"Accuratezza sul mini dataset:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "xJ4kKPFp6AhP",
        "outputId": "243ffa1f-8441-4f49-b631-45e4ad46f4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)         â”‚        \u001b[38;5;34m16,000\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling1d_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             â”‚           \u001b[38;5;34m272\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m17\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,000</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling1d_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,289\u001b[0m (63.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,289</span> (63.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,289\u001b[0m (63.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,289</span> (63.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuratezza sul mini dataset: 0.6666666865348816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Recurrent Neural Network (RNN)"
      ],
      "metadata": {
        "id": "BdGAUExdPPuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finora abbiamo trattato le frasi come **sacchetti di parole** (bag of words) o liste di token su cui calcolare una media.\n",
        "\n",
        "Ma spesso l'**ordine** delle parole Ã¨ fondamentale:\n",
        "- \"non Ã¨ buono\" â‰  \"Ã¨ buono\"\n",
        "- \"io mangio il cane\" â‰  \"il cane mi mangia\"\n",
        "\n",
        "Serve un modello che legga la sequenza **passo dopo passo**, mantenendo una memoria del passato: le **RNN** (Recurrent Neural Networks).\n",
        "\n",
        "### 2.1 RNN semplici\n",
        "\n",
        "Una RNN elabora una sequenza `xâ‚, xâ‚‚, ..., x_T` e produce stati nascosti `hâ‚, hâ‚‚, ..., h_T`.\n",
        "\n",
        "A ogni passo:\n",
        "- prende in input il token corrente `x_t`\n",
        "- aggiorna uno stato interno `h_t` usando `h_{t-1}`\n",
        "\n",
        "In pseudocodice:\n",
        "\n",
        "`h_t = f(Wx * x_t + Wh * h_{t-1} + b)`\n",
        "\n",
        "Problema: **vanishing gradient**\n",
        "- quando la sequenza Ã¨ lunga, il gradiente tende a svanire\n",
        "- la rete \"dimentica\" il contesto lontano\n",
        "\n",
        "### 2.2 LSTM: Long Short-Term Memory\n",
        "\n",
        "Le **LSTM** sono un tipo speciale di RNN progettate per:\n",
        "- imparare **dipendenze a lungo termine**\n",
        "- evitare il problema del vanishing gradient\n",
        "\n",
        "Dentro una LSTM ci sono:\n",
        "- uno **stato della cella** (memoria a lungo termine)\n",
        "- uno **stato nascosto** (output al tempo t)\n",
        "- tre \"porte\" (gate):\n",
        "  - **forget gate**: cosa dimentico?\n",
        "  - **input gate**: cosa aggiungo alla memoria?\n",
        "  - **output gate**: cosa rendo visibile in uscita?\n",
        "\n",
        "Non serve entrare nei dettagli matematici, ma Ã¨ importante l'idea: la LSTM decide cosa ricordare e cosa dimenticare della sequenza.\n",
        "\n",
        "### 2.3 GRU: Gated Recurrent Unit\n",
        "\n",
        "Le **GRU** sono una variante piÃ¹ semplice delle LSTM:\n",
        "- meno parametri\n",
        "- concettualmente simili (anche loro usano dei gate)\n",
        "- spesso prestazioni simili alle LSTM\n",
        "\n",
        "In pratica:\n",
        "- se non hai vincoli particolari, **LSTM e GRU sono entrambe valide scelte**\n",
        "\n",
        "### 2.4 Uso tipico per testo\n",
        "\n",
        "Pipeline classica per classificazione di testo con RNN:\n",
        "\n",
        "1. testo â†’ token â†’ sequenze di interi\n",
        "2. `Embedding` per trasformare gli interi in vettori\n",
        "3. `LSTM` o `GRU` per leggere la sequenza\n",
        "4. Dense finale + attivazione (`sigmoid` per binaria, `softmax` per multi-classe)\n",
        "\n",
        "#### Esempio: sentiment analysis su recensioni di film (IMDB) con LSTM\n"
      ],
      "metadata": {
        "id": "pOXCYeqiPap4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carichiamo il dataset IMDB\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "vocab_size = 10000\n",
        "maxlen = 200\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "print(\"Esempio di recensione (id):\", x_train[0][:20], \"...\")\n",
        "print(\"Etichetta:\", y_train[0])\n",
        "\n",
        "# Padding delle sequenze per avere lunghezza fissa\n",
        "x_train_pad = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test_pad = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "print(\"Shape x_train_pad:\", x_train_pad.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbdXJcxd6lIi",
        "outputId": "6f9067d6-32f4-4292-f51d-7ccbd6394573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Esempio di recensione (id): [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25] ...\n",
            "Etichetta: 1\n",
            "Shape x_train_pad: (25000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "\n",
        "inputs = keras.Input(shape=(maxlen,))\n",
        "x = layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "x = layers.LSTM(64)(x)  # si puÃ² mettere return_sequences=True per piÃ¹ LSTM di fila\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model_lstm = keras.Model(inputs, outputs)\n",
        "\n",
        "model_lstm.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model_lstm.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "c3R8m2fiQEki",
        "outputId": "41b8b23c-1b13-4ef9-f12e-3ae4fd759ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚       \u001b[38;5;34m640,000\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m33\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m675,137\u001b[0m (2.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">675,137</span> (2.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m675,137\u001b[0m (2.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">675,137</span> (2.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_lstm = model_lstm.fit(\n",
        "    x_train_pad, y_train,\n",
        "    epochs=3,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_loss_lstm, test_acc_lstm = model_lstm.evaluate(x_test_pad, y_test)\n",
        "print(\"Accuratezza LSTM su IMDB:\", test_acc_lstm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksIQpOoOQHJZ",
        "outputId": "c1b343c7-45ff-4268-e356-0f21b6ea5436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 203ms/step - accuracy: 0.6456 - loss: 0.6065 - val_accuracy: 0.8626 - val_loss: 0.3194\n",
            "Epoch 2/3\n",
            "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 206ms/step - accuracy: 0.9003 - loss: 0.2560 - val_accuracy: 0.8620 - val_loss: 0.3283\n",
            "Epoch 3/3\n",
            "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 204ms/step - accuracy: 0.9302 - loss: 0.1870 - val_accuracy: 0.8732 - val_loss: 0.3208\n",
            "\u001b[1m782/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.8668 - loss: 0.3389\n",
            "Accuratezza LSTM su IMDB: 0.8687199950218201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Stessa architettura ma con GRU\n",
        "\"\"\"\n",
        "\n",
        "inputs = keras.Input(shape=(maxlen,))\n",
        "x = layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "x = layers.GRU(64)(x)  # GRU al posto della LSTM\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model_gru = keras.Model(inputs, outputs)\n",
        "\n",
        "model_gru.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model_gru.summary()\n",
        "\n",
        "history_gru = model_gru.fit(\n",
        "    x_train_pad, y_train,\n",
        "    epochs=3,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_loss_gru, test_acc_gru = model_gru.evaluate(x_test_pad, y_test)\n",
        "print(\"Accuratezza GRU su IMDB:\", test_acc_gru)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "esjsF-HYQK-5",
        "outputId": "37eef8a7-ffa7-4371-cfdf-cc676a9a5ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚       \u001b[38;5;34m640,000\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ gru (\u001b[38;5;33mGRU\u001b[0m)                       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m24,960\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m33\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,960</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m667,073\u001b[0m (2.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">667,073</span> (2.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m667,073\u001b[0m (2.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">667,073</span> (2.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 214ms/step - accuracy: 0.6020 - loss: 0.6447 - val_accuracy: 0.8392 - val_loss: 0.3685\n",
            "Epoch 2/3\n",
            "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 217ms/step - accuracy: 0.8824 - loss: 0.2858 - val_accuracy: 0.8432 - val_loss: 0.3548\n",
            "Epoch 3/3\n",
            "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 214ms/step - accuracy: 0.9216 - loss: 0.2044 - val_accuracy: 0.8758 - val_loss: 0.3153\n",
            "\u001b[1m782/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.8647 - loss: 0.3395\n",
            "Accuratezza GRU su IMDB: 0.8664399981498718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers"
      ],
      "metadata": {
        "id": "p1zBcGNpQiWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I **Transformers** sono una famiglia di modelli introdotta nel 2017\n",
        "(\"Attention is All You Need\") e hanno rivoluzionato NLP.\n",
        "\n",
        "Sono alla base dei moderni **Large Language Models (LLM)**.\n",
        "\n",
        "### 3.1 Limiti delle RNN\n",
        "\n",
        "Le RNN (LSTM/GRU) leggono la sequenza **passo dopo passo**:\n",
        "- non possono parallelizzare bene il calcolo\n",
        "- faticano con sequenze molto lunghe\n",
        "- la distanza tra due token lontani Ã¨ difficile da gestire\n",
        "\n",
        "### 3.2 Idea chiave: Self-Attention\n",
        "\n",
        "Il **self-attention** permette al modello di far \"guardare\" ogni parola a tutte le altre parole della frase\n",
        "\n",
        "Per ogni token:\n",
        "- calcola quanto deve â€œprestare attenzioneâ€ agli altri token\n",
        "- combina le informazioni in base a questi pesi di attenzione\n",
        "\n",
        "In pratica:\n",
        "- la rappresentazione di una parola tiene conto del **contesto globale** della frase\n",
        "- il calcolo Ã¨ altamente **parallelizzabile**\n",
        "\n",
        "### 3.3 Query, Key, Value (Q, K, V)\n",
        "\n",
        "Per ogni token, il modello calcola tre vettori:\n",
        "- **Query (Q)**\n",
        "- **Key (K)**\n",
        "- **Value (V)**\n",
        "\n",
        "I pesi di attenzione vengono calcolati confrontando:\n",
        "- le Query di un token con le Key di tutti gli altri\n",
        "- poi vengono combinati i Value in base a questi pesi\n",
        "\n",
        "### 3.4 Positional Encoding\n",
        "\n",
        "I Transformers non hanno una struttura sequenziale interna come le RNN.\n",
        "PerciÃ² devono sapere **in che posizione** si trova ogni token.\n",
        "\n",
        "Si aggiunge quindi un **positional encoding**:\n",
        "- un vettore che codifica la posizione\n",
        "- sommato all'embedding della parola\n",
        "\n",
        "### 3.5 Vantaggi e svantaggi dei Transformers\n",
        "\n",
        "Vantaggi:\n",
        "- parallelizzabili (si elaborano tutti i token in parallelo)\n",
        "- gestiscono bene dipendenze anche molto **lontane** nella frase\n",
        "- scalano molto bene con dati e modello\n",
        "- sono la base di BERT, GPT, T5, ecc.\n",
        "\n",
        "Svantaggi:\n",
        "- CapacitÃ  limitata dei token in input\n",
        "- Serve ampia potenza computazionale per l'allenamento\n",
        "\n",
        "### 3.6 Architettura base di un Transformer Encoder\n",
        "\n",
        "Un blocco tipico di **encoder**:\n",
        "\n",
        "1. **Multi-Head Self-Attention**\n",
        "2. **Add & Layer Normalization**\n",
        "3. **Feed-Forward Network (2 Dense)**\n",
        "4. **Add & Layer Normalization**\n",
        "\n",
        "Ripetuto piÃ¹ volte (stack di blocchi encoder).\n",
        "\n",
        "### 3.7 Esempio didattico: classificazione di testo con un piccolo Transformer\n",
        "\n",
        "Useremo:\n",
        "- `TextVectorization` per tokenizzare\n",
        "- `Embedding`\n",
        "- un semplice **encoder Transformer** fatto con:\n",
        "  - `MultiHeadAttention`\n",
        "  - `LayerNormalization`\n",
        "  - feed-forward Dense\n",
        "- Pooling + Dense per classificazione\n"
      ],
      "metadata": {
        "id": "pOz0CT9CQm1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classificazione di un testo con le Transformers\n",
        "\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# Mini dataset\n",
        "testi = np.array([\n",
        "    \"mi piace molto questo film\",\n",
        "    \"questo film Ã¨ stato noioso\",\n",
        "    \"adoro questo prodotto\",\n",
        "    \"odio profondamente questo prodotto\",\n",
        "    \"esperienza fantastica sono molto soddisfatto\",\n",
        "    \"pessima esperienza non lo comprerÃ² mai piÃ¹\",\n",
        "    \"film bellissimo da rivedere\",\n",
        "    \"film orrendo da dimenticare\",\n",
        "])\n",
        "\n",
        "etichette = np.array([1, 0, 1, 0, 1, 0, 1, 0])\n",
        "\n",
        "vocab_size = 2000\n",
        "maxlen = 12\n",
        "\n",
        "vectorizer = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=maxlen\n",
        ")\n",
        "\n",
        "vectorizer.adapt(testi)\n",
        "X = vectorizer(testi)\n",
        "\n",
        "print(\"Shape X:\", X.shape)\n",
        "print(\"Un esempio di sequenza:\", X[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ds1dpwWRH9r",
        "outputId": "8f25fde6-6c3d-4afb-a107-3c194fc52e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape X: (8, 12)\n",
            "Un esempio di sequenza: tf.Tensor([21 15  5  2  3  0  0  0  0  0  0  0], shape=(12,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, num_heads, dim_ff, dropout=0.1):\n",
        "    \"\"\"\n",
        "    Semplice encoder Transformer:\n",
        "    - MultiHeadAttention (self-attention)\n",
        "    - Add & LayerNorm\n",
        "    - Feed-forward (Dense -> Dense)\n",
        "    - Add & LayerNorm\n",
        "    \"\"\"\n",
        "\n",
        "    # Self-attention\n",
        "    x = layers.MultiHeadAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=inputs.shape[-1],\n",
        "        dropout=dropout\n",
        "    )(inputs, inputs)\n",
        "    x = layers.Add()([x, inputs])\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    # Feed-forward\n",
        "    ff = layers.Dense(dim_ff, activation=\"relu\")(x)\n",
        "    ff = layers.Dense(inputs.shape[-1])(ff)\n",
        "    x = layers.Add()([x, ff])\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "2locQZblRM-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 32\n",
        "num_heads = 2\n",
        "dim_ff = 64\n",
        "\n",
        "inputs = keras.Input(shape=(maxlen,), dtype=tf.int32)\n",
        "\n",
        "# Embedding + positional encoding semplice (learnable)\n",
        "x = layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "\n",
        "# Aggiungiamo un positional embedding learnable\n",
        "positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "positional_embedding = layers.Embedding(input_dim=maxlen, output_dim=embedding_dim)(positions)\n",
        "x = x + positional_embedding  # broadcasting sulle batch\n",
        "\n",
        "# Applichiamo il nostro encoder Transformer\n",
        "x = transformer_encoder(x, num_heads=num_heads, dim_ff=dim_ff)\n",
        "\n",
        "# Pooling sulla dimensione temporale (media)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "# Classificatore finale\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model_transf = keras.Model(inputs, outputs)\n",
        "\n",
        "model_transf.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model_transf.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "Z2fEH_YJRemN",
        "outputId": "7db47519-e086-43b7-9394-e9ca2fc29a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_4       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_4         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚     \u001b[38;5;34m64,000\u001b[0m â”‚ input_layer_4[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add (\u001b[38;5;33mAdd\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚      \u001b[38;5;34m8,416\u001b[0m â”‚ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_1 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalization â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚         \u001b[38;5;34m64\u001b[0m â”‚ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚      \u001b[38;5;34m2,112\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_2 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚         \u001b[38;5;34m64\u001b[0m â”‚ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_10 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m1,056\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_11 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m33\u001b[0m â”‚ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_4       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_4         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">64,000</span> â”‚ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,416</span> â”‚ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalization â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> â”‚ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> â”‚ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m77,825\u001b[0m (304.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,825</span> (304.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m77,825\u001b[0m (304.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,825</span> (304.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_transf = model_transf.fit(\n",
        "    X, etichette,\n",
        "    epochs=50,\n",
        "    batch_size=2,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "loss_t, acc_t = model_transf.evaluate(X, etichette, verbose=0)\n",
        "print(\"Accuratezza Transformer sul mini dataset:\", acc_t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZnY3A0ZRfBB",
        "outputId": "7c31af6b-fe8a-41e7-b28c-7c54a7415466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuratezza Transformer sul mini dataset: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Esercitazione pratica"
      ],
      "metadata": {
        "id": "lMxhSiAiP6wA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RDPlZ0SwRoko"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}